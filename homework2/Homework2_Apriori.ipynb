{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Discovery of Frequent Itemsets and Association Rules\n",
    "\n",
    "**Course:** ID2222 Data Mining (KTH Royal Institute of Technology)  \n",
    "**Authors:** [Your Names]  \n",
    "**Date:** [Insert Date]\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Objective\n",
    "This notebook implements the **A-Priori algorithm** to find **frequent itemsets** and (optionally) to generate **association rules**.\n",
    "\n",
    "We will:\n",
    "1. Load a dataset of transactions (`T10I4D100K.dat`)\n",
    "2. Implement the A-Priori algorithm using **pandas**\n",
    "3. Find all frequent itemsets with support ‚â• *s*\n",
    "4. (Bonus) Generate association rules with confidence ‚â• *c*\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions: 100000\n"
     ]
    }
   ],
   "source": [
    "# Path to dataset (you will upload it in VS Code / GitHub)\n",
    "file_path = \"data/T10I4D100K.dat\"\n",
    "\n",
    "# Each line = one transaction, items separated by spaces\n",
    "transactions = []\n",
    "with open(file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        items = list(map(int, line.strip().split()))\n",
    "        transactions.append(items)\n",
    "\n",
    "# Convert into a pandas DataFrame\n",
    "df = pd.DataFrame({\"TransactionID\": range(1, len(transactions) + 1), \"Items\": transactions})\n",
    "\n",
    "df.head()\n",
    "\n",
    "# dimensions of the dataset\n",
    "num_transactions = df.shape[0]\n",
    "print(f\"Number of transactions: {num_transactions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Support: 1000\n",
      "Minimum Confidence: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Minimum support (as an absolute count)\n",
    "# Let's start with a threshold that gives interpretable results without overloading memory.\n",
    "# The dataset has 100,000 transactions, so 0.5% = 500 transactions.\n",
    "min_support = 1000\n",
    "\n",
    "# Minimum confidence for association rules (between 0 and 1)\n",
    "min_confidence = 0.6\n",
    "\n",
    "print(f\"Minimum Support: {min_support}\")\n",
    "print(f\"Minimum Confidence: {min_confidence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_itemsets(transactions, min_support):\n",
    "    \"\"\"Run the Apriori algorithm to find all frequent itemsets above the given support.\"\"\"\n",
    "    # Step 1: Count single items\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_counts[frozenset([item])] += 1\n",
    "\n",
    "    # Filter by min_support\n",
    "    frequent_itemsets = {item: count for item, count in item_counts.items() if count >= min_support}\n",
    "    all_frequent = dict(frequent_itemsets)\n",
    "\n",
    "    k = 2\n",
    "    current_Lk = list(frequent_itemsets.keys())\n",
    "\n",
    "    # Step 2: Iteratively find larger itemsets\n",
    "    while current_Lk:\n",
    "        # Generate candidate itemsets of size k\n",
    "        candidate_itemsets = set(\n",
    "            [i.union(j) for i in current_Lk for j in current_Lk if len(i.union(j)) == k]\n",
    "        )\n",
    "\n",
    "        candidate_counts = defaultdict(int)\n",
    "\n",
    "        # Count occurrences of candidates in all transactions\n",
    "        for transaction in transactions:\n",
    "            tset = set(transaction)\n",
    "            for candidate in candidate_itemsets:\n",
    "                if candidate.issubset(tset):\n",
    "                    candidate_counts[candidate] += 1\n",
    "\n",
    "        # Filter by min_support\n",
    "        current_Lk = [item for item, count in candidate_counts.items() if count >= min_support]\n",
    "        frequent_k = {item: count for item, count in candidate_counts.items() if count >= min_support}\n",
    "\n",
    "        # Add to results\n",
    "        all_frequent.update(frequent_k)\n",
    "        k += 1\n",
    "\n",
    "    return all_frequent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent itemsets found: 385\n",
      "Itemset: {25}, Support: 1395\n",
      "Itemset: {52}, Support: 1983\n",
      "Itemset: {240}, Support: 1399\n",
      "Itemset: {274}, Support: 2628\n",
      "Itemset: {368}, Support: 7828\n",
      "Itemset: {448}, Support: 1370\n",
      "Itemset: {538}, Support: 3982\n",
      "Itemset: {561}, Support: 2783\n",
      "Itemset: {630}, Support: 1523\n",
      "Itemset: {687}, Support: 1762\n"
     ]
    }
   ],
   "source": [
    "frequent_itemsets = get_frequent_itemsets(transactions, min_support)\n",
    "\n",
    "print(f\"Number of frequent itemsets found: {len(frequent_itemsets)}\")\n",
    "\n",
    "# Show top 10\n",
    "for itemset, support in list(frequent_itemsets.items())[:10]:\n",
    "    print(f\"Itemset: {set(itemset)}, Support: {support}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Itemset  Support\n",
      "0             (25,)     1395\n",
      "1             (52,)     1983\n",
      "2            (240,)     1399\n",
      "3            (274,)     2628\n",
      "4            (368,)     7828\n",
      "..              ...      ...\n",
      "380      (368, 829)     1194\n",
      "381      (217, 346)     1336\n",
      "382      (368, 682)     1193\n",
      "383      (722, 390)     1042\n",
      "384  (704, 825, 39)     1035\n",
      "\n",
      "[385 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "freq_df = pd.DataFrame(\n",
    "    [(tuple(itemset), support) for itemset, support in frequent_itemsets.items()],\n",
    "    columns=[\"Itemset\", \"Support\"]\n",
    ")\n",
    "freq_df.sort_values(by=\"Support\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antecedent</th>\n",
       "      <th>Consequent</th>\n",
       "      <th>Support</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(704,)</td>\n",
       "      <td>(825,)</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.6143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(704,)</td>\n",
       "      <td>(39,)</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.6171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(825, 39)</td>\n",
       "      <td>(704,)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(704, 39)</td>\n",
       "      <td>(825,)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(704, 825)</td>\n",
       "      <td>(39,)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.9392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Antecedent Consequent  Support  Confidence\n",
       "0      (704,)     (825,)   0.0110      0.6143\n",
       "1      (704,)      (39,)   0.0111      0.6171\n",
       "2   (825, 39)     (704,)   0.0103      0.8719\n",
       "3   (704, 39)     (825,)   0.0103      0.9350\n",
       "4  (704, 825)      (39,)   0.0103      0.9392"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_rules(frequent_itemsets, min_confidence, num_transactions):\n",
    "    \"\"\"Generate association rules from frequent itemsets.\"\"\"\n",
    "    rules = []\n",
    "    for itemset, support_count in frequent_itemsets.items():\n",
    "        if len(itemset) < 2:\n",
    "            continue\n",
    "        for consequent_size in range(1, len(itemset)):\n",
    "            for consequent in itertools.combinations(itemset, consequent_size):\n",
    "                consequent = frozenset(consequent)\n",
    "                antecedent = itemset - consequent\n",
    "                if not antecedent:\n",
    "                    continue\n",
    "                support_XY = support_count / num_transactions\n",
    "                support_X = frequent_itemsets.get(antecedent, 0) / num_transactions\n",
    "                if support_X > 0:\n",
    "                    confidence = support_XY / support_X\n",
    "                    if confidence >= min_confidence:\n",
    "                        rules.append({\n",
    "                            \"Antecedent\": tuple(antecedent),\n",
    "                            \"Consequent\": tuple(consequent),\n",
    "                            \"Support\": round(support_XY, 4),\n",
    "                            \"Confidence\": round(confidence, 4)\n",
    "                        })\n",
    "    return pd.DataFrame(rules)\n",
    "\n",
    "rules_df = generate_rules(frequent_itemsets, min_confidence, len(transactions))\n",
    "rules_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Association Rules by Confidence:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Antecedent</th>\n",
       "      <th>Consequent</th>\n",
       "      <th>Support</th>\n",
       "      <th>Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(704, 825)</td>\n",
       "      <td>(39,)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(704, 39)</td>\n",
       "      <td>(825,)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(825, 39)</td>\n",
       "      <td>(704,)</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(704,)</td>\n",
       "      <td>(39,)</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.6171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(704,)</td>\n",
       "      <td>(825,)</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.6143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Antecedent Consequent  Support  Confidence\n",
       "4  (704, 825)      (39,)   0.0103      0.9392\n",
       "3   (704, 39)     (825,)   0.0103      0.9350\n",
       "2   (825, 39)     (704,)   0.0103      0.8719\n",
       "1      (704,)      (39,)   0.0111      0.6171\n",
       "0      (704,)     (825,)   0.0110      0.6143"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 10 Association Rules by Confidence:\")\n",
    "rules_df.sort_values(by=\"Confidence\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Conclusions\n",
    "\n",
    "- The **A-Priori algorithm** efficiently finds frequent itemsets by iteratively expanding candidate sets.  \n",
    "- Using the **monotonicity property of support**, it avoids unnecessary computations.  \n",
    "- With reasonable support thresholds (e.g., 0.5% of transactions), the number of candidates remains manageable.\n",
    "- The **association rules** provide interpretable patterns, e.g., *‚Äúif {X, Y}, then Z‚Äù*, useful in market basket analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è How to Run\n",
    "1. Upload `T10I4D100K.dat` into the same folder as this notebook (in VS Code or GitHub).  \n",
    "2. Open the notebook in VS Code or JupyterLab.  \n",
    "3. Run all cells sequentially (Shift + Enter).  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
